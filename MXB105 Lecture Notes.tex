%!TEX program = xelatex
\documentclass{article}
\usepackage{template}

\usepackage{chngcntr} % Reset counter within sections
\usepackage{multicol}

% Create nice frames
\usepackage{mdframed}
\mdfsetup{skipabove=\topskip,skipbelow=\topskip}
\mdfdefinestyle{exampledefault}{%
	rightline=true,
	innerleftmargin=10,innerrightmargin=10,
	leftmargin=20,rightmargin=20,
	topline=false,bottomline=false,
	frametitlefont=\bf\large
}
\mdfdefinestyle{exampledefaultcols}{%
	rightline=false,leftline=true,
	innerleftmargin=5,innerrightmargin=5,
	leftmargin=0,rightmargin=0,
	topline=false,bottomline=false,
	frametitlefont=\bf\large
}

\counterwithin*{equation}{section}
\counterwithin*{equation}{subsection}

\pagestyle{fancy}
\setlength\headheight{24pt}

\lhead{\className}
\rhead{\leftmark}
\cfoot{\thepage}

\newcommand{\uniTitle}{Queensland University of Technology}
\newcommand{\className}{Calculus and Differential Equations}
\newcommand{\classTime}{2021, Semester 2}
\newcommand{\classInstructorName}{Dr Vivien Challis}
\newcommand{\authorName}{Tarang Janawalkar}
\newcommand{\authorStudentNumber}{n11032201}
\newcommand{\classCode}{MXB105}

\usepackage[
    type={CC},
    modifier={by-nc-sa},
    version={4.0},
    imagewidth={5em},
    hyphenation={raggedright}
]{doclicense}

\date{}

\begin{document}

\begin{titlepage}
    \vspace*{\fill}
    \begin{center}
        \LARGE
        \textbf{\className}
        \texorpdfstring{\\}{ }
        \uniTitle
        \texorpdfstring{\\}{ }
        \texorpdfstring{\vspace{0.3in}}{ }
        \normalsize\textit{\classInstructorName}
        \texorpdfstring{\\}{ }
        \classTime
    \end{center}
    \begin{center}
        \textbf{\authorName}
    \end{center}
    \vspace*{\fill}
    \doclicenseThis
    \thispagestyle{empty}
\end{titlepage}
\newpage

\tableofcontents
\newpage

\section{Integration Techniques}
\subsection{Table of Derivatives}
Let $f(x)$ be a function, and $a\in\mathbb{R}$ be a constant.
\begin{table}[H]
    \renewcommand*{\arraystretch}{1.5}
    \centering
    \begin{tabular}{>{$}c<{$} | >{$}c<{$}}
        \toprule
            f & \dv{f}{x} \\
        \midrule
            x^a & a x^{a-1} \\
            \sqrt{x} & \displaystyle \frac{1}{2\sqrt{x}} \\
            a^x & \ln{\left( a \right)} a^x \\
            \e^x & \e^x \\
            \log_a{x}, \: a\in \mathbb{R}\backslash\left\{ 0 \right\} & \displaystyle \frac{1}{a\ln{x}} \\[8pt]
            \ln{x} & \displaystyle \frac{1}{x} \\[5pt]
        \bottomrule
    \end{tabular}
    \begin{tabular}{>{$}c<{$} | >{$}c<{$}}
        \toprule
            f & \dv{f}{x} \\
        \midrule
            a & 0 \\
            x & 1 \\
            a_1 u(x) \pm a_2 v(x) & \displaystyle a_1\dv{u}{x} \pm a_2\dv{v}{x} \\[8pt]
            u(x)v(x) & \displaystyle \dv{u}{x}v + u\dv{v}{x} \\[10pt]
            \displaystyle \frac{u(x)}{v(x)} & \displaystyle \frac{\dv{u}{x}v - u\dv{v}{x}}{{v(x)}^2} \\[8pt]
            u\bigl( v\left( x \right) \bigr) & \displaystyle \dv{u}{v}\dv{v}{x} \\[5pt]
        \bottomrule
    \end{tabular}
\end{table}
\begin{table}[H]
    \renewcommand*{\arraystretch}{1.5}
    \centering
    \begin{tabular}{>{$}c<{$} | >{$}c<{$}}
        \toprule
            f & \dv{f}{x} \\
        \midrule
            \sin{\left( ax \right)} &  a\cos{\left( ax \right)} \\
            \cos{\left( ax \right)} & -a\sin{\left( ax \right)} \\
            \tan{\left( ax \right)} &  a\sec^2{\left( ax \right)} \\
            \cot{\left( ax \right)} & -a\csc^2{\left( ax \right)} \\
            \sec{\left( ax \right)} &  a\sec{\left( ax \right)}\tan{\left( ax \right)} \\
            \csc{\left( ax \right)} & -a\csc{\left( ax \right)}\cot{\left( ax \right)} \\[5pt]
        \bottomrule
    \end{tabular}
    \begin{tabular}{>{$}c<{$} | >{$}c<{$}}
        \toprule
            f & \dv{f}{x} \\
        \midrule
            \arcsin{\left( ax \right)} & \displaystyle  \frac{a}{\sqrt{1-a^2x^2}} \\[8pt]
            \arccos{\left( ax \right)} & \displaystyle -\frac{a}{\sqrt{1-a^2x^2}} \\[8pt]
            \arctan{\left( ax \right)} & \displaystyle  \frac{a}{1+a^2x^2} \\[8pt]
            \arccot{\left( ax \right)} & \displaystyle -\frac{a}{1+a^2x^2} \\[8pt]
            \arcsec{\left( ax \right)} & \displaystyle  \frac{1}{x\sqrt{a^2x^2 - 1}} \\[8pt]
            \arccsc{\left( ax \right)} & \displaystyle -\frac{1}{x\sqrt{a^2x^2 - 1}} \\[8pt]
        \bottomrule
    \end{tabular}
\end{table}
\begin{table}[H]
    \renewcommand*{\arraystretch}{1.5}
    \centering
    \hspace*{-1cm}
    \begin{tabular}{>{$}c<{$} | >{$}c<{$}}
        \toprule
            f & \dv{f}{x} \\
        \midrule
            \sinh{\left( ax \right)} &  a\cosh{\left( ax \right)} \\
            \cosh{\left( ax \right)} &  a\sinh{\left( ax \right)} \\
            \tanh{\left( ax \right)} &  a\sech^2{\left( ax \right)} \\
            \coth{\left( ax \right)} & -a\csch^2{\left( ax \right)} \\
            \sech{\left( ax \right)} & -a\sech{\left( ax \right)}\tan{\left( ax \right)} \\
            \csch{\left( ax \right)} & -a\csch{\left( ax \right)}\cot{\left( ax \right)} \\[5pt]
        \bottomrule
    \end{tabular}
    \begin{tabular}{>{$}c<{$} | >{$}c<{$}}
        \toprule
            f & \dv{f}{x} \\
        \midrule
            \arcsinh{\left( ax \right)} & \displaystyle  \frac{a}{\sqrt{1+a^2x^2}} \\[8pt]
            \arccosh{\left( ax \right)} & \displaystyle  \frac{a}{\sqrt{1-a^2x^2}} \\[8pt]
            \arctanh{\left( ax \right)} & \displaystyle  \frac{a}{1-a^2x^2} \\[8pt]
        \bottomrule
    \end{tabular}
    \begin{tabular}{>{$}c<{$} | >{$}c<{$}}
        \toprule
            f & \dv{f}{x} \\
        \midrule
            \arccoth{\left( ax \right)} & \displaystyle  \frac{a}{1-a^2x^2} \\[8pt]
            \arcsech{\left( ax \right)} & \displaystyle -\frac{1}{a\left( 1+ax \right)\sqrt{\frac{1-ax}{1+ax}}} \\[8pt]
            \arccsch{\left( ax \right)} & \displaystyle -\frac{1}{ax^2\sqrt{1+\frac{1}{a^2x^2}}} \\[8pt]
        \bottomrule
    \end{tabular}
    \hspace*{-1cm}
    \caption{Derivatives of Elementary Functions}
\end{table}
\subsection{Trigonometric Identities}
\subsubsection{Pythagorean Identities}
\begin{equation*}
	\sin^2{\left( x \right)} + \cos^2{\left( x \right)} = 1
\end{equation*}
Dividing by either the sine or cosine function gives:
\begin{align*}
	\tan^2{\left( x \right)} + 1 &= \sec^2{\left( x \right)} \\
	1 + \cot^2{\left( x \right)} &= \csc^2{\left( x \right)}
\end{align*}
\subsubsection{Double-Angle Identities}
\begin{align*}
    \sin{\left( 2x \right)} &= 2\sin{\left( x \right)}\cos{\left( x \right)}              & \csc{\left( 2x \right)} &= \frac{\sec{\left( x \right)}\csc{\left( x \right)}}{2} \\[5pt]
    \cos{\left( 2x \right)} &= \cos^2{\left( x \right)} - \sin^2{\left( x \right)}        & \sec{\left( 2x \right)} &= \frac{\sec^2{\left( x \right)}\csc^2{\left( x \right)}}{\csc^2{\left( x \right)}-\sec^2{\left( x \right)}} \\[5pt]
	\tan{\left( 2x \right)} &= \frac{2\tan{\left( x \right)}}{1-\tan^2{\left( x \right)}} & \cot{\left( 2x \right)} &= \frac{\cot^2{\left( x \right)}-1}{2\cot{\left( x \right)}}
\end{align*}
\subsubsection{Power Reducing Identities}
\begin{align*}
    \sin^2{\left( x \right)} &= \frac{1-\cos{\left( 2x \right)}}{2}                         & \csc^2{\left( x \right)} &= \frac{2}{1-\cos{\left( 2x \right)}} \\[5pt]
    \cos^2{\left( x \right)} &= \frac{1+\cos{\left( 2x \right)}}{2}                         & \sec^2{\left( x \right)} &= \frac{2}{1+\cos{\left( 2x \right)}} \\[5pt]
	\tan^2{\left( x \right)} &= \frac{1-\cos{\left( 2x \right)}}{1+\cos{\left( 2x \right)}} & \cot^2{\left( x \right)} &= \frac{1+\cos{\left( 2x \right)}}{1-\cos{\left( 2x \right)}}
\end{align*}
\subsection{Partial Fractions}
\begin{definition}[Partial Fraction Decomposition]
    \textbf{Partial fraction decomposition} is a \linebreak method where a rational function $\displaystyle \frac{P(x)}{Q(x)}$ is rewritten as a sum of fraction.
\end{definition}
\begin{table}[H]
    \renewcommand*{\arraystretch}{1.5}
    \centering
    \begin{tabular}{c | c}
        \toprule
            \textbf{Factor in denominator} & \textbf{Term in partial fraction decomposition} \\
        \midrule
            $ax+b$ & $\displaystyle \frac{A}{ax+b}$ \\[10pt]
            $\left(ax+b\right)^k, \: k \in \mathbb{N}$ & $\displaystyle \frac{A_1}{ax+b} + \frac{A_2}{\left( ax+b \right)^2} + \cdots + \frac{A_k}{\left( ax+b \right)^k}$ \\[10pt]
            $ax^2+bx+c$ & $\displaystyle \frac{A}{ax^2+bx+c}$ \\[10pt]
            $\left(ax^2+bx+c\right)^k, \: k \in \mathbb{N}$ & $\displaystyle \frac{A_1x+B_1}{ax^2+bx+c} + \frac{A_2}{\left( ax+b \right)^2} + \cdots + \frac{A_k}{\left( ax+b \right)^k}$ \\[10pt]
        \bottomrule
    \end{tabular}
    \caption{Partial Fraction Forms}
\end{table}
\subsection{Integration by Parts}
\begin{theorem}
\begin{equation*}
    \int u \dd{v} = uv - \int v \dd{u}
\end{equation*}
\end{theorem}
% \begin{proof}
%     \begin{align*}
%         \dv{}{x}\left( u(x)v(x) \right) &= \dv{u(x)}{x}v(x) + u(x)\dv{v(x)}{x} \\
%         u(x)\dv{v(x)}{x} &= \dv{}{x}\left( u(x)v(x) \right) - \dv{u(x)}{x}v(x) \\
%         \int u(x)\dv{v(x)}{x} \dd{x} &= \int \dv{}{x}\left( u(x)v(x) \right) \dd{x} - \int \dv{u(x)}{x}v(x) \dd{x} \\
%         \int u(x)\dd{v(x)} &= u(x)v(x) - \int v(x) \dd{u(x)}
%     \end{align*}
% \end{proof}
\subsection{Integration by Substitution}
\begin{theorem}
    \begin{equation*}
        \int f\bigl(g\left( x \right)\bigr)\dv{g(x)}{x} \dd{x} = \int f(u) \dd{u}, \: \text{where } u = g(x)
    \end{equation*}
\end{theorem}
\subsection{Trigonometric Substitutions}
\begin{table}[H]
    \renewcommand*{\arraystretch}{1.5}
    \centering
    \begin{tabular}{>{$}c<{$} | >{$}c<{$} >{$}c<{$} | >{$}c<{$}}
        \toprule
        \text{\textbf{Form}} & \text{\textbf{Substitution}} & \text{\textbf{Result}} & \text{\textbf{Domain}} \\
        \midrule
        \left(a^2-b^2x^2\right)^n & \displaystyle x=\frac{a}{b}\sin{\left( \theta \right)} & a^2\cos^2{\left( \theta \right)} & \theta\in \left[ -\frac{\pi}{2},\: \frac{\pi}{2} \right] \\[8pt]
        \left(a^2+b^2x^2\right)^n & \displaystyle x=\frac{a}{b}\tan{\left( \theta \right)} & a^2\sec^2{\left( \theta \right)} & \theta\in \left( -\frac{\pi}{2},\: \frac{\pi}{2} \right) \\[8pt]
        \left(b^2x^2-a^2\right)^n & \displaystyle x=\frac{a}{b}\sec{\left( \theta \right)} & a^2\tan^2{\left( \theta \right)} & \theta\in \left[ 0,\: \frac{\pi}{2} \right) \cup \left(\frac{\pi}{2},\: \pi\right] \\
        \bottomrule
    \end{tabular}
    \caption{Trigonometric substitutions for various forms.}
\end{table}
\newpage
\section{Limits, Continuity and Differentiability}
\subsection{Limits}
\begin{theorem}[Limits]
    $\displaystyle\lim_{x\to x_0} f(x)$ exists if and only if
    $\displaystyle\lim_{x\to {x_0}^+} f(x)$ and $\displaystyle\lim_{x\to {x_0}^-} f(x)$
    exist and are equal.
\end{theorem}
\begin{definition}[Finite limits using the $\varepsilon$-$\delta$ definition]
    \begin{equation*}
		\lim_{x\to x_0} f(x) = L \iff \forall\varepsilon>0: \exists\delta>0: \forall x \in I: 0<\abs{x-x_0}<\delta \implies \abs{f(x)-L}<\varepsilon
	\end{equation*}
\end{definition}
\begin{theorem}[L'H\^opital's Rule]
    For two differentiable functions $f(x)$ and $g(x)$.
    If $\displaystyle \lim_{x\to x_0}f(x)=\lim_{x\to x_0}g(x)=0$,
    or $\displaystyle \lim_{x\to x_0}f(x)=\displaystyle \lim_{x\to x_0}g(x)=\pm\infty$,
    then
    $\lim_{x\to x_0}\frac{f(x)}{g(x)} = \lim_{x\to x_0}\frac{f'(x)}{g'(x)}$.
\end{theorem}
\subsection{Continuity}
\begin{theorem}[Continuity at a Point]
    $f(x)$ is continuous at $c$ iff $\displaystyle \lim_{x\to c} f(x) = f(c)$.
\end{theorem}
\begin{theorem}[Continuity over an Interval]
    $f(x)$ is continuous on $I$ if $f(x)$ is continuous for all $x\in I$.
\begin{itemize}
    \item $f(x)$ is continuous on $I:\left( a,\:b \right)$ if it is continuous
        for all $x\in I$.
    \item $f(x)$ is continuous on $I:\left[ a,\:b \right]$ if it is continuous
        for all $x\in I$, but only right continuous at $a$ and left continuous at $b$.
\end{itemize}
    If $f(x)$  is continuous on $\left(-\infty,\:\infty\right)$, $f(x)$ is
    continuous everywhere.
\end{theorem}
\begin{theorem}[Intermediate Value Theorem]
    If $f(x)$ is continuous on $I:\left[ a, \: b \right]$ and $c$ is any number
    between $f(a)$ and $f(b)$, inclusive, then there exists an $x\in I$ such
    that $f(x)=c$.
\end{theorem}
\subsection{Differentiability}
\begin{theorem}[Differentiability]
    $f(x)$ is differentiable at $x=x_0$ iff
    \begin{equation*}
        \lim_{x\to x_0} \frac{f(x)-f(x_0)}{x-x_0}
    \end{equation*}
    exists. When this limit exists, it defines the derivative
    \begin{equation*}
        \left.\dv{f}{x}\right|_{x=x_0} = \lim_{h\to 0} \frac{f(x_0+h)-f(x_0)}{h}
    \end{equation*}
\end{theorem}
\begin{theorem}
    $f(x)$ is differentiable on $I$ if $f(x)$ is differentiable for all
    $x_0\in I$.
\end{theorem}
\begin{theorem}
    Differentiability implies continuity.
\end{theorem}
\begin{theorem}[Mean Value Theorem]
    If $f(x)$ is continuous on $I:\left[ a,\:b \right]$ and differentiable on
    $I$, then there exists a point $c\in I$ such that
    \begin{equation*}
        \left.\dv{f}{x}\right|_{x=c}=\frac{f(b)-f(a)}{b-a}
    \end{equation*}
\end{theorem}
\newpage
\section{Definite Integrals}
\begin{theorem}
    If $f(x)$ is continuous on an interval $I:\left[ a,\:b \right]$, then the
    net signed area $A$ between the graph of $f(x)$ and the interval $I$ is
    \begin{equation*}
        A = \int_a^b f(x) \dd{x}
    \end{equation*}
\end{theorem}
\begin{figure}[H]
	\begin{mdframed}[style=exampledefault,frametitle={Properties of Definite Integrals}]
		\begin{theorem}
			Suppose that $f(x)$ and $g(x)$ are continuous on the interval $I$,
            with $a,\:b,\:c\in I$ and $k\in\mathbb{R}$ then
			\begin{enumerate}[label=\normalfont\alph*)]
				\item $\displaystyle\int_a^a f(x) \dd{x} = 0$.
				\item $\displaystyle\int_a^b f(x) \dd{x} = -\int_b^a f(x) \dd{x}$.
				\item $\displaystyle\int_a^b kf(x) \dd{x} = k\int_a^b f(x) \dd{x}$.
				\item $\displaystyle\int_a^b \bigl(f(x) \pm g(x)\bigr) \dd{x} = \int_a^b f(x) \dd{x} \pm \int_a^b g(x) \dd{x}$.
				\item $\displaystyle\int_a^b f(x) \dd{x} = \int_a^c f(x) \dd{x} + \int_c^b f(x) \dd{x}$.
			\end{enumerate}
		\end{theorem}
	\end{mdframed}
\end{figure}
\subsection{Riemann Sums}
\begin{theorem}
    Let $A$ be the area under $f(x)$ on the interval $\left[ a,\:b \right]$,
    then
    \begin{equation*}
        \int_a^b f(x) \dd{x} = \lim_{\max{\Delta x_k}\to 0} \sum_{k=1}^n f(x_k) \Delta x_k
    \end{equation*}
    where $n$ is the number of rectangles, $x_k$ is the centre of the rectangle
    $k$, and $\Delta x_k$ is the width of the rectangle $k$. If every rectangle
    has the same width, then
    \begin{equation*}
        \forall k:\Delta x_k = \frac{b-a}{n}
    \end{equation*}
\end{theorem}
\subsection{Fundamental Theorem of Calculus}
The fundamental theorem of calculus provides a logical connection between
infinite series (definite integrals) and antiderivatives
(indefinite integrals).
\begin{theorem}[The Fundamental Theorem of Calculus: Part 1]
    If $f(x)$ is continuous on $\left[ a,\:b \right]$ and $F$ is any
    antiderivative of $f$ on $\left[ a,\:b \right]$ then
    \begin{equation*}
        \int_a^b f(x)\dd{x} = F(b) - F(a)
    \end{equation*}
    Equivalently
    \begin{equation*}
        \int_a^b \dv{x}F(x) \dd{x} = F(b) - F(a) \equiv \left.F(x)\right|_a^b
    \end{equation*}
\end{theorem}
\begin{theorem}[The Fundamental Theorem of Calculus: Part 2]
    If $f(x)$ is continuous on $I$ then it has an antiderivative on $I$. In
    particular, if $a\in I$, then the function $F$ defined by
    \begin{equation*}
        F(x) = \int_a^x f(t)\dd{t}
    \end{equation*}
    is an antiderivative of $f(x)$. That is,
    \begin{equation*}
        \dv{x}F(x) = f(x) \equiv \dv{x}\int_a^x f(t) \dd{t} = f(x)
    \end{equation*}
\end{theorem}
\begin{theorem}
    Differentiation and integration are inverse operations.
\end{theorem}
\newpage
\subsection{Taylor and Maclaurin Polynomials}
\begin{theorem}[Taylor Polynomials]
    If $f(x)$ is a $n$ differentiable function at $x_0$, then the $n$th degree
    Taylor polynomial for $f(x)$ near $x_0$, is given by
    \begin{equation*}
        f(x) \approx p_n(x) = \sum_{k=0}^n \frac{f^{\left( k \right)}(x_0)}{k!} \left( x-x_0 \right)^k
    \end{equation*}
\end{theorem}
\begin{theorem}[Maclaurin Polynomials]
    Evaluating a Taylor polynomial near $0$, gives the $n$th degree Maclaurin
    polynomial for $f(x)$
    \begin{equation*}
        f(x) \approx p_n(x) = \sum_{k=0}^n \frac{f^{\left( k \right)}(0)}{k!} x^k
    \end{equation*}
\end{theorem}
\begin{theorem}[Error in Approximation]
    Let $R_n(x)$ denote the difference between $f(x)$ and its $n$th Taylor
    polynomial, that is
    \begin{equation*}
        R_n(x) = f(x) - p_n(x) = f(x) - \sum_{k=0}^n \frac{f^{\left( k \right)}(x_0)}{k!} \left( x-x_0 \right)^k = \frac{f^{\left( n+1 \right)}(s)}{\left( n+1 \right)!} \left( x-x_0 \right)^{n+1}
    \end{equation*}
    where $s$ is between $x_0$ and $x$.
\end{theorem}
\newpage
\section{Taylor and Maclaurin Series}
\subsection{Infinite Series}
\begin{definition}[Taylor Series]
    If $f(x)$  has derivatives of all orders at $x_0$, then the Taylor series
    for $f(x)$ about $x=x_0$ is given by
    \begin{equation*}
        f(x) = \sum_{n=0}^{\infty} \frac{f^{\left( n \right)}(x_0)}{n!}\left( x-x_0 \right)^n
    \end{equation*}
\end{definition}
\begin{definition}[Maclaurin Series]
    If a Taylor series is centred on $x_0=0$, it is called a Maclaurin series,
    defined by
    \begin{equation*}
        f(x) = \sum_{n=0}^{\infty} \frac{f^{\left( n \right)}(0)}{n!} x^n
    \end{equation*}
\end{definition}
\begin{definition}[Power Series]
    Both Taylor and Maclaurin series are examples of \textbf{power series},
    which are defined as follows
    \begin{equation*}
        \sum_{n=0}^{\infty} c_n\left( x-x_0 \right)^n
    \end{equation*}
\end{definition}
\subsection{Convergence}
\begin{theorem}[Convergence of a Taylor Series]
    The equality
    \begin{equation*}
        f(x) = \sum_{n=0}^{\infty} \frac{f^{\left( n \right)}(x_0)}{n!} \left( x-x_0 \right)^n
    \end{equation*}
    holds at a point $x$ iff
    \begin{align*}
        \lim_{n\to\infty} \left[ f(x) - \sum_{n=0}^{\infty} \frac{f^{\left( n \right)}(x_0)}{n!} \left( x-x_0 \right)^n \right] &= 0 \\
        \lim_{n\to\infty} R_n(x) &= 0
    \end{align*}
\end{theorem}
\begin{definition}[Interval of Convergence]
    The interval of convergence for a power series is the set of $x$ values for
    which that series converges.
\end{definition}
\begin{definition}[Radius of Convergence]
    The radius of convergence $R$ is a nonnegative real number or $\infty$ such
    that
    a power series converges if
    \begin{equation*}
        \abs{x - a} < R
    \end{equation*}
    and diverges if
    \begin{equation*}
        \abs{x - a} > R
    \end{equation*}
    The behaviour of the power series on the boundary, that is, where
    $\abs{x - a} = R$, can be determined by substituting $x = R + a$ for the
    upper boundary, and $x = -R + a$ for the lower boundary.
\end{definition}
\subsection{Convergence Tests}
For any power series of the form $\displaystyle\sum_{i=i_0}^\infty a_i$.
\begin{mdframed}[style=exampledefaultcols,frametitle={Alternating Series}]
    \textbf{Conditions} $a_i = \left( -1 \right)^i b_i$ or
    $a_i = \left( -1 \right)^{i+1} b_i$. $b_i>0$.
    \begin{equation*}
        \text{Is $b_{i+1}\leqslant b_i$ \& $\lim_{i\to\infty}b_i=0$?}\:
        \begin{cases}
            \text{YES} & \text{$\sum a_i$ Converges} \\
            \text{NO} & \text{Inconclusive}
        \end{cases}
    \end{equation*}
\end{mdframed}
\begin{mdframed}[style=exampledefaultcols,frametitle={Ratio Test}]
    \begin{equation*}
        \text{Is $\lim_{i\to\infty}\abs{\frac{a_{i+1}}{a_i}} < 1$?}\:
        \begin{cases}
            \text{YES} & \text{$\sum a_i$ Converges} \\
            \text{NO} & \text{$\sum a_i$ Diverges}
        \end{cases}
    \end{equation*}
    The ratio test is inconclusive if
    $\displaystyle \lim_{i\to\infty}\frac{a_{i+1}}{a_i} = 1$.
\end{mdframed}
\subsection{Table of Maclaurin Series}
\begin{table}[H]
    \centering
    \begin{tabular}{c | c | c}
        \toprule
        \textbf{Function} & \textbf{Series} & \textbf{Interval of Convergence} \\
        \midrule
        $\e^{x}$ & $\displaystyle \sum_{n=0}^{\infty} \frac{x^n}{n!}$ & $-\infty < x < \infty$ \\[14pt]
        $\sin{\left( x \right)}$ & $\displaystyle \sum_{n=0}^{\infty} \frac{\left( -1 \right)^n}{\left( 2n+1 \right)!} x^{2n+1}$ & $-\infty < x < \infty$ \\[14pt]
        $\cos{\left( x \right)}$ & $\displaystyle \sum_{n=0}^{\infty} \frac{\left( -1 \right)^n}{\left( 2n \right)!} x^{2n}$ & $-\infty < x < \infty$ \\[14pt]
        $\frac{1}{1-x}$ & $\displaystyle \sum_{n=0}^{\infty} x^n$ & $-1 < x < 1$ \\
        \bottomrule
    \end{tabular}
    \caption{Maclaurin Series of Common Functions}
    % \label{}
\end{table}
\newpage
\section{Multivariable Calculus}
\subsection{Multivariable Functions}
\begin{definition}
    A function is multivariable if its domain consists of several variables. In
    the reals, these functions are defined
    \begin{equation*}
        f:\mathbb{R}^n\to\mathbb{R}
    \end{equation*}
\end{definition}
\subsection{Level Curves}
\begin{definition}
    Level curves or \textit{contour curves} of a function of two variables is a
    curve along which the function has constant value.
    \begin{equation*}
        L_c\left( f \right) = \left\{ \left( x,\: y \right) : f\left(x,\: y\right) = c\right\}
    \end{equation*}
\end{definition}
The level curves of a function can be determined by substituting $z=c$, and
solving for $y$.
\subsection{Limits and Continuity}
\begin{definition}[Finite Limit of Multivariable Functions using the
    $\varepsilon$-$\delta$ Definition]
    \begin{align*}
		&\lim_{(x_1,\: \ldots,\: x_n)\to (c_1,\: \ldots,\: c_n)} f(x_1,\: \ldots,\: x_n) = L \\
        &\iff\forall\varepsilon>0: \exists\delta>0: \forall (x_1,\: \ldots,\: x_n) \in I: \\
        &0<\abs{x_1-c_1,\: \ldots,\: x_n-c_n}<\delta \implies \abs{f(x_1,\: \ldots,\: x_n)-L}<\varepsilon
	\end{align*}
\end{definition}
\begin{theorem}[Limits along Smooth Curves]
    If $f(x,\: y) \to L$ as $(x,\: y) \to (x_0,\: y_0)$, then
    $\displaystyle \lim_{(x,\: y) \to (x_0,\: y_0)} = L$ along any smooth
    curve.
\end{theorem}
\begin{theorem}[Existence of a Limit]
    If the limit of $f(x,\: y)$ changes along different smooth curves, then
    $\displaystyle \lim_{(x,\: y) \to (x_0,\: y_0)}$ does not exist.
\end{theorem}
\begin{theorem}[Continuity of Multivariable Functions]
    A function $f(x_1,\: \ldots,\: x_n)$ is continuous at
    $(c_1,\: \ldots,\: c_n)$ iff
    \begin{equation*}
        \lim_{(x_1,\: \ldots,\: x_n)\to (c_1,\: \ldots,\: c_n)} f(x_1,\: \ldots,\: x_n) = f(c_1,\: \ldots,\: c_n)
    \end{equation*}
\end{theorem}
Recognising continuous functions:
\begin{itemize}
    \item A sum, difference or product of continuous functions is continuous.
    \item A quotient of continuous functions is continuous expect where the
        denominator is zero.
    \item A composition of continuous functions is continuous.
\end{itemize}
\subsection{Partial Derivatives}
\begin{definition}[Partial Differentiation]
    The partial derivative of a multivariable function is its derivative with
    respect to one of those variables, while the others are held constant.
    \begin{equation*}
        \pdv{f}{x_i} = \lim_{h \to 0} \frac{f(x_1,\: \ldots,\: x_{i-1},\: x_i+h,\: x_{i+1},\: \ldots,\: x_n) - f(x_1,\: \ldots,\: x_n)}{h}
    \end{equation*}
\end{definition}
\subsection{The Gradient Vector}
\begin{definition}
    Let $\symbf{\nabla}$, pronounced ``del'', denote the vector differential
    operator defined as follows
    \begin{equation*}
        \symbf{\nabla} = \mqty[\partial_{x_1} \\ \partial_{x_2} \\ \vdots \\ \partial_{x_n}]
    \end{equation*}
\end{definition}
\subsection{Multivariable Chain Rule}
\begin{definition}
    Let $f=f(\symbfit{x}(t_1,\: \ldots,\: t_n))$ be the composition of $f$ with
    $\symbfit{x}=\mqty[x_1 & \cdots & x_m]$, then the partial derivative of $f$
    with respect to $t_i$ is given by
    \begin{equation*}
        \pdv{f}{t_i} = \symbf{\nabla}f \vdot \partial_{t_i}\symbfit{x}
    \end{equation*}
\end{definition}
\subsection{Directional Derivatives}
\begin{definition}
    The directional derivative $\symbf{\nabla}_{\symbfit{u}}f$ is the rate at
    which the function $f$ changes in the direction $\symbfit{u}$.
    \begin{align*}
        \symbf{\nabla}_{\symbfit{u}}f &= \lim_{h \to 0} \frac{f(\symbfit{x} + h\symbfit{u}) - f(\symbfit{x})}{h} \\
        &= \symbf{\nabla}f \vdot \symbfit{u}
    \end{align*}
    where the slope is given by $\norm{\symbf{\nabla}_{\symbfit{u}}f}$.
\end{definition}
\begin{remark}
    The directional derivative of $f$ can be denoted in several ways:
    \begin{equation*}
        \symbf{\nabla}_{\symbfit{u}}f = D_{\symbfit{u}} f = \partial_{\symbfit{u}} f = \pdv{f}{\symbfit{u}}
    \end{equation*}
\end{remark}
\begin{theorem}[Direction of Greatest Ascent]
    The direction of greatest ascent is given by
    \begin{equation*}
        \max_{\norm{\symbfit{u}} = 1} \symbf{\nabla}_{\symbfit{u}}f = \symbf{\nabla}f
    \end{equation*}
    where the slope is given by $\norm{\symbf{\nabla}f}$.
\end{theorem}
\begin{theorem}[Direction of Greatest Descent]
    The direction of greatest descent is given by
    \begin{equation*}
        \min_{\norm{\symbfit{u}} = 1} \symbf{\nabla}_{\symbfit{u}}f = -\symbf{\nabla}f
    \end{equation*}
    where the slope is given by $-\norm{\symbf{\nabla}f}$.
\end{theorem}
\begin{proof}
    Given that $\symbfit{u}$ is a unit vector, the dot product definition
    gives
    \begin{align}
        \symbf{\nabla}_{\symbfit{u}}f &= \symbf{\nabla}f \vdot \symbfit{u} \nonumber \\
        &= \norm{\symbf{\nabla}f} \norm{\symbfit{u}} \cos{\left( \theta \right)} \nonumber \\
        &= \norm{\symbf{\nabla}f} \cos{\left( \theta \right)} \label{directional_derivative}
    \end{align}
    \hyperref[directional_derivative]{Equation \ref{directional_derivative}} is
    maximised when $\cos{\left( \theta \right)}$ is maximised. Thus the
    maximum slope is given by
    \begin{equation*}
        \max \symbf{\nabla}_{\symbfit{u}}f = \norm{\symbf{\nabla}f}
    \end{equation*}
    and the direction of greatest ascent is given by
    \begin{equation*}
        \symbfit{u} = \symbf{\nabla}f
    \end{equation*}
\end{proof}
\begin{theorem}[The Gradient is Normal to the Level Curves of $f$]
    If $\symbf{\nabla}f = 0$, then $\symbf{\nabla}f$ is normal to the level
    curves of $f$ at any point $(c_1,\: \ldots,\: c_n)$.
\end{theorem}
\subsection{Higher-Order Partial Derivatives}
\begin{definition}
    Higher-order partial derivatives can be denoted using three different
    notation. The following table shows the mixed partial derivative of
    $f(x,\: y)$ w.r.t. $x$ then $y$.
    \begin{table}[H]
        \centering
        \begin{tabular}{c c c}
            \toprule
            \textbf{Leibniz} & \textbf{Euler} & \textbf{Legendre} \\
            \midrule
            $\displaystyle\pdv{f}{y}{x}$ & $\partial_{x y}{f}$ & $f_{x y}$ \\
            \bottomrule
        \end{tabular}
        \caption{Mixed Partial Derivative Notation}
        % \label{}
    \end{table}
    For partial derivatives w.r.t. the same variable, a superscript can be used
    in Euler notation.
    \begin{table}[H]
        \centering
        \begin{tabular}{c c c}
            \toprule
            \textbf{Leibniz} & \textbf{Euler} & \textbf{Legendre} \\
            \midrule
            $\displaystyle\pdv[2]{f}{x}$ & $\partial^2_{x}{f}$ & $f_{x x}$ \\
            \bottomrule
        \end{tabular}
        \caption{Second-Order Partial Derivative Notation}
        % \label{}
    \end{table}
\end{definition}
\subsection{Hessian Matrix}
\begin{definition}
    Let the Hessian matrix $\symbf{H}$ be the matrix of second-order partial
    derivative operators defined as shown below
    \begin{equation*}
        \symbf{H} =
        \mqty[
            \partial^2_{x_1} & \cdots & \partial_{x_nx_1} \\
            \vdots & \ddots & \vdots \\
            \partial_{x_1x_n} & \cdots & \partial^2_{x_n}
        ]
    \end{equation*}
\end{definition}
\subsection{Critical Points}
\newpage
\section{Double and Triple Integrals}
\subsection{Double Integrals}
\begin{theorem}
    Divide the rectangular region of $R$ into $n$ rectangles with sides
    parallel to the coordinate axes.
    Discard rectangles which contain any points outside of $R$.
    Choose an arbitrary point in each remaining rectangle.
    The area of the $k$th remaining rectangle is $\Delta A_k$.
    The arbitrary point in the $k$th remaining rectangle is
    $({x_k}^\ast,\: {y_k}^\ast)$.
    The Riemann sum is
    \begin{equation*}
        \iint\limits_{R} f(x,\: y)  \dd{A}
        = \sum_{k=1}^{\infty} f({x_k}^\ast,\: {y_k}^\ast) \Delta{}A_k
    \end{equation*}
\end{theorem}
\begin{figure}[H]
	\begin{mdframed}[style=exampledefault,frametitle={Properties of Double Integrals}]
		\begin{theorem}
            Suppose that $f(x,\: y) $ and $g(x,\: y)$ are continuous on $R$
            and $R$ can be subdivided into $R_1$ and $R_2$then
			\begin{enumerate}[label=\normalfont\alph*)]
				\item $\displaystyle\iint\limits_R kf(x,\: y) \dd{A}
                    = k\iint\limits_R f(x,\: y) \dd{A}$.
				\item $\displaystyle\iint\limits_R \bigl(f(x,\: y) + g(x,\: y)\bigr) \dd{A}
                    = \iint\limits_R f(x,\: y) \dd{A} + \iint\limits_R g(x,\: y) \dd{A}$.
                \item $\displaystyle\iint\limits_R f(x,\: y) \dd{A}
                    = \iint\limits_{R_1} f(x,\: y) \dd{A} + \iint\limits_{R_2} f(x,\: y) \dd{A}$.
			\end{enumerate}
		\end{theorem}
	\end{mdframed}
\end{figure}
\subsection{Triple Integrals}
\begin{definition}
    A triple integral is of a function is the net signed volume
    defined over a finite closed solid region $G$ in an $xyz$ coordinate system.
\end{definition}
\begin{theorem}
    Divide the bounding box of $G$ into $n$ boxes with sides parallel to the coordinate planes.
    Discard boxes which contain any points outside of $G$.
    Choose an arbitrary point in each remaining box.
    The volume of the $k$th remaining box is $\Delta V_k$.
    The arbitrary point in the $k$th remaining box is
    $({x_k}^\ast,\: {y_k}^\ast,\: {z_k}^\ast)$.
    The Riemann sum is
    \begin{equation*}
        \iiint\limits_{G} f(x,\: y,\: z)  \dd{V}
        = \sum_{k=1}^{\infty} f({x_k}^\ast,\: {y_k}^\ast,\: {z_k}^\ast) \Delta{}V_k
    \end{equation*}
\end{theorem}
\begin{figure}[H]
	\begin{mdframed}[style=exampledefault,frametitle={Properties of Triple Integrals}]
		\begin{theorem}
            Suppose that $f(x,\: y,\: z) $ and $g(x,\: y,\: z)$ are continuous on $G$
            and $G$ can be subdivided into $G_1$ and $G_2$then
			\begin{enumerate}[label=\normalfont\alph*)]
				\item $\displaystyle\iiint\limits_G kf(x,\: y,\: z) \dd{V}
                    = k\iiint\limits_G f(x,\: y,\: z) \dd{V}$.
				\item $\displaystyle\iiint\limits_G \bigl(f(x,\: y,\: z) + g(x,\: y,\: z)\bigr) \dd{V}
                    = \iiint\limits_G f(x,\: y,\: z) \dd{V} + \iiint\limits_G g(x,\: y,\: z) \dd{V}$.
                \item $\displaystyle\iiint\limits_G f(x,\: y,\: z) \dd{V}
                    = \iiint\limits_{G_1} f(x,\: y,\: z) \dd{V} + \iiint\limits_{G_2} f(x,\: y,\: z) \dd{V}$.
			\end{enumerate}
		\end{theorem}
	\end{mdframed}
\end{figure}
\newpage
\section{Vector-Valued Functions}
% Conventions:
% Component-form vectors shall be written like $\avec{x(t),\:y(t),\:(z(t)}$
\begin{definition}
    A Vector-Valued Function or VVF is some function
    with domain $\mathbb{R}$ and codomain $\mathbb{R}^n$.
    For example, $\symbf{r}:\mathbb{R}\to\mathbb{R}^3$
    is a VVF with $\symbf{r}(t)=\avec{x(t),\:y(t),\:(z(t)}$ where
    $x,\:y,\:z: \mathbb{R}\to\mathbb{R}$.
\end{definition}
\begin{theorem}
    The domain of $\symbf{r}(t)$ is the intersection of the domains
    of its components.
\end{theorem}
\begin{definition}[Orientation]
    The orientation of $\symbf{r}(t)$ is the direction of increasing parameter ($t$).
\end{definition}
\begin{theorem}[Limits of VVFs]
    The limit of a VFF is the vector of the limits of its components.
    E.g. $\lim_{x\to{}a} \symbf{r}(t)
    = \avec{\lim_{x\to{}a}x(t),\:\lim_{x\to{}a}y(t),\:\lim_{x\to{}a}z(t)}$
\end{theorem}
\begin{theorem}[Derivatives of VVFs]
    The derivative of a VFF is the vector of the derivatives of its components.
    For example, $\symbf{r'}(t) = \avec{x'(t),\:y'(t),\:z'(t)}$
\end{theorem}
\begin{theorem}[Integration of VVFs]
    The integral of a VFF is the vector of the integrals of its components.
    E.g. $\int\symbf{r}(t)\dd{t}
    = \avec{\int x(t) \dd{t},\:\int y(t) \dd{t},\:\int z(t) \dd{t}}$
\end{theorem}
\begin{remark}
    When integrating a VVF, each component has its own constant of integration.
\end{remark}
\begin{definition}[VVF of a Line]
    A line can be determined by a point which it passes through, $\symbfit{P_0}$
    and a vector the line is parallel to, $\symbfit{v}$.
    The VVF of a line can be written as $\symbf{r}(t)=\symbfit{P_0}+t\symbfit{v}$.
\end{definition}
\begin{definition}[Tangent Line of a VVF]
    When some VVF $\symbf{r}(t)$ is differentiable at
    $t_0$ and $\symbf{r'}(t_0)\ne\symbfit{0}$, the tangent line of $\symbf{r}(t)$
    is $\symbf{l}(t) = \symbf{r}(t_0)+t\symbf{r'}(t_0)$.
\end{definition}
\begin{definition}[Arc Length of a VVF]
    The arc length $S$ of some VVF $\symbf{r}(t)$ is the distance along $\symbf{r}(t)$
    between two points where $t=a$ and $t=b$ and the curve is smooth (defined and nonzero).
    The arc length is given by
    \[ S = \int_a^b||\:\symbf{r'}(t)\:||\dd{t} \]
\end{definition}
\newpage
\section{First-Order Differential Equations}
\newpage
\section{Second-Order Differential Equations}
\newpage

\end{document}
